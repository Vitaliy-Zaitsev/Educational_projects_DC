{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TextClassificationPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем лишний столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tweets = df_tweets[['text', 'toxic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим дисбаланс классов целевого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10161213369158527"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.toxic.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** В данных почти 160000 строк. Из них негативные только 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение моделей с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для экономии времени возьмем из наших данных 2000 объектов сохранив исходный дисбаланс класов целевого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_sample, _ = train_test_split(df_tweets, train_size=200, random_state=12345, stratify=df_tweets.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_sample.toxic.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Используем предобученную модель с домена https://huggingface.co/martin-ha/toxic-comment-model\n",
    "Не создаем эмбердинги, а сразу получаем предсказания модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb5b40d57984735a2b8e0a801384443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"martin-ha/toxic-comment-model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "pipeline =  TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "y_pred = []\n",
    "for text in tqdm(df_tweets_sample['text']):\n",
    "    pred = pipeline(text[:512])\n",
    "    y_pred.append(1 if pred[0]['label'] == 'toxic' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727274"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_tweets_sample['toxic'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень быстрый результат, но метрика ниже заданного порога."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Используем предобученную модель Conversational BERT, English с домена <a href='https://docs.deeppavlov.ai/en/master/features/models/bert.html'> DeepPavlov</a> для векторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer_config = transformers.BertConfig.from_json_file(\n",
    "    'ds_bert/tokenizer_config.json')\n",
    "\n",
    "tokenizer = transformers.BertTokenizer(\n",
    "    vocab_file='ds_bert/vocab.txt', config=tokenizer_config)\n",
    "\n",
    "tokenized = df_tweets_sample['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512))\n",
    "\n",
    "max_len = len(max(tokenized, key=len))\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ds_bert/pytorch_model.bin were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = transformers.BertConfig.from_json_file(\n",
    "    'ds_bert/config.json')\n",
    "model = transformers.BertModel.from_pretrained(\n",
    "    'ds_bert/pytorch_model.bin', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbc05585163468d9b9bea62574b2c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "embeddings = []\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Модели LGBMClassifier и LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor': LogisticRegression(class_weight='balanced', random_state=12345)}\n",
      "0.6542857142857142\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 7.84 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\123\\WPy64-31090\\python-3.10.9.amd64\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(metric='f1', objective='binary', is_unbalance=True)\n",
    "model_lr = LogisticRegression(random_state=12345, class_weight='balanced')\n",
    "\n",
    "pipe = Pipeline([('regressor', model)])\n",
    "\n",
    "param_grid = [\n",
    "    {'regressor': [model_lgb],\n",
    "     'regressor__max_depth': [10],              \n",
    "     'regressor__learning_rate': np.arange(0.1, 1, 0.1),\n",
    "     'regressor__n_estimators': [2000]},\n",
    "    {'regressor': [model_lr]}\n",
    "]\n",
    "\n",
    "model_lgbm_bert = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=scv,\n",
    "    scoring='f1',\n",
    "    n_jobs = -1)\n",
    "\n",
    "model_lgbm_bert.fit(features, df_tweets_sample['toxic'])\n",
    "\n",
    "\n",
    "print(model_lgbm_bert.best_params_)\n",
    "print(model_lgbm_bert.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'regressor': LogisticRegression(class_weight=...</td>\n",
       "      <td>0.654286</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040089</td>\n",
       "      <td>0.002362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'regressor': LGBMClassifier(is_unbalance=True...</td>\n",
       "      <td>0.579048</td>\n",
       "      <td>2</td>\n",
       "      <td>2.996058</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'regressor': LGBMClassifier(is_unbalance=True...</td>\n",
       "      <td>0.521905</td>\n",
       "      <td>3</td>\n",
       "      <td>2.483533</td>\n",
       "      <td>0.001607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'regressor': LGBMClassifier(is_unbalance=True...</td>\n",
       "      <td>0.499048</td>\n",
       "      <td>4</td>\n",
       "      <td>2.158290</td>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'regressor': LGBMClassifier(is_unbalance=True...</td>\n",
       "      <td>0.432381</td>\n",
       "      <td>5</td>\n",
       "      <td>1.930929</td>\n",
       "      <td>0.004825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "0  {'regressor': LogisticRegression(class_weight=...         0.654286   \n",
       "1  {'regressor': LGBMClassifier(is_unbalance=True...         0.579048   \n",
       "2  {'regressor': LGBMClassifier(is_unbalance=True...         0.521905   \n",
       "3  {'regressor': LGBMClassifier(is_unbalance=True...         0.499048   \n",
       "4  {'regressor': LGBMClassifier(is_unbalance=True...         0.432381   \n",
       "\n",
       "   rank_test_score  mean_fit_time  mean_score_time  \n",
       "0                1       0.040089         0.002362  \n",
       "1                2       2.996058         0.004032  \n",
       "2                3       2.483533         0.001607  \n",
       "3                4       2.158290         0.004028  \n",
       "4                5       1.930929         0.004825  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_result = (pd.DataFrame(model_lgbm_bert.cv_results_)\n",
    "  [['params', 'mean_test_score', 'rank_test_score', 'mean_fit_time', 'mean_score_time']]\n",
    "  .sort_values(by='mean_test_score', ascending=False)\n",
    "  .head()).reset_index(drop=True)\n",
    "bert_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'LGBMClassifier':[], 'LogisticRegression':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['LGBMClassifier'].append(bert_result['mean_test_score'][1].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['LogisticRegression'].append(bert_result['mean_test_score'][0].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод** Лучший результат у LogisticRegression. Но все же он намного ниже требуемого. Возможно с увеличением количества объектов увеличится и качество модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение моделей с TF-IDF и CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лемматизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos_new(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Виталик\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae486dcf9f74e92a4b5c247db1bdaec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52df74b9effb4efb9294eee98b224b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 29s\n",
      "Wall time: 7min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nltk.download('popular')\n",
    "\n",
    "\n",
    "def text_transform(text):\n",
    "    #удаляем неалфавитные символы\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # токенизируем слова\n",
    "    text = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(text)\n",
    "    # лемматирзируем слова\n",
    "    text = [lemmatize.lemmatize(word, get_wordnet_pos_new(tag)) for word, tag in pos_tags] \n",
    "            #if not word in set(stopwords.words('english'))]\n",
    "    # соединяем слова\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "lemmatize = nltk.WordNetLemmatizer()\n",
    "df_tweets['text'] = df_tweets['text'].progress_apply(remove_stopwords)\n",
    "df_tweets['lemm_text'] = df_tweets['text'].progress_apply(text_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation Why edits username Hardcore Metall...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why edits username Hardcore Metall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches background colour I'm seemin...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He match background colour I m seemingly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm trying edit war. It's guy constan...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m try edit war It s guy constantly r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" More I can't real suggestions improvement - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t real suggestion improvement I won...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, hero. Any chance remember page that'...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir hero Any chance remember page that s on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation Why edits username Hardcore Metall...      0   \n",
       "1  D'aww! He matches background colour I'm seemin...      0   \n",
       "2  Hey man, I'm trying edit war. It's guy constan...      0   \n",
       "3  \" More I can't real suggestions improvement - ...      0   \n",
       "4  You, sir, hero. Any chance remember page that'...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  Explanation Why edits username Hardcore Metall...  \n",
       "1  D aww He match background colour I m seemingly...  \n",
       "2  Hey man I m try edit war It s guy constantly r...  \n",
       "3  More I can t real suggestion improvement I won...  \n",
       "4    You sir hero Any chance remember page that s on  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разделим наши данные на train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_tweets['lemm_text'], df_tweets['toxic'],\n",
    "                                                    test_size=.2,\n",
    "                                                    random_state=12345,\n",
    "                                                    stratify=df_tweets.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(dtype=np.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подбор гиперпараметров и обучение моделей LogisticRegression и LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor': LGBMClassifier(is_unbalance=True, learning_rate=0.3, max_depth=100, metric='f1',\n",
      "               n_estimators=600, objective='binary', reg_alpha=0.1), 'regressor__is_unbalance': True, 'regressor__learning_rate': 0.3, 'regressor__max_depth': 100, 'regressor__n_estimators': 600, 'regressor__reg_alpha': 0.1, 'vect': CountVectorizer(dtype=<class 'numpy.float32'>)}\n",
      "0.7778393629047834\n",
      "CPU times: total: 2min 43s\n",
      "Wall time: 8min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "model = LogisticRegression(random_state=12345, class_weight='balanced')\n",
    "model_lgb = lgb.LGBMClassifier(metric='f1',                               \n",
    "                               objective='binary'                               \n",
    "                               )\n",
    "\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [('vect', tfidf_vectorizer),\n",
    "    ('regressor', model)]\n",
    ")\n",
    "\n",
    "param_grid = [{'vect':[tfidf_vectorizer, count_vect],\n",
    "              'regressor': [model],\n",
    "              'regressor__C': range(1, 20, 1)},\n",
    "              {'vect':[tfidf_vectorizer, count_vect],\n",
    "              'regressor': [model_lgb],\n",
    "              'regressor__max_depth': [100],              \n",
    "              'regressor__learning_rate': [.3],\n",
    "              'regressor__n_estimators':  [600],\n",
    "              'regressor__is_unbalance': [True],\n",
    "              'regressor__reg_alpha': [.1]\n",
    "             }\n",
    "             ]\n",
    "   \n",
    "\n",
    "scv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "model_grid = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    cv=scv,\n",
    "    scoring='f1',\n",
    "    n_jobs = -1\n",
    "    )\n",
    "model_grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(model_grid.best_params_)\n",
    "print(model_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результаты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor</th>\n",
       "      <th>param_vect</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier(is_unbalance=True, learning_rat...</td>\n",
       "      <td>CountVectorizer(dtype=&lt;class 'numpy.float32'&gt;)</td>\n",
       "      <td>0.777839</td>\n",
       "      <td>1</td>\n",
       "      <td>76.192374</td>\n",
       "      <td>5.484644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMClassifier(is_unbalance=True, learning_rat...</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>0.774050</td>\n",
       "      <td>2</td>\n",
       "      <td>224.143465</td>\n",
       "      <td>5.005721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>0.768352</td>\n",
       "      <td>3</td>\n",
       "      <td>14.457293</td>\n",
       "      <td>1.685853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>0.768107</td>\n",
       "      <td>4</td>\n",
       "      <td>13.656884</td>\n",
       "      <td>1.708761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression(class_weight='balanced', ra...</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>0.768052</td>\n",
       "      <td>5</td>\n",
       "      <td>14.293548</td>\n",
       "      <td>1.601098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     param_regressor  \\\n",
       "0  LGBMClassifier(is_unbalance=True, learning_rat...   \n",
       "1  LGBMClassifier(is_unbalance=True, learning_rat...   \n",
       "2  LogisticRegression(class_weight='balanced', ra...   \n",
       "3  LogisticRegression(class_weight='balanced', ra...   \n",
       "4  LogisticRegression(class_weight='balanced', ra...   \n",
       "\n",
       "                                       param_vect  mean_test_score  \\\n",
       "0  CountVectorizer(dtype=<class 'numpy.float32'>)         0.777839   \n",
       "1                               TfidfVectorizer()         0.774050   \n",
       "2                               TfidfVectorizer()         0.768352   \n",
       "3                               TfidfVectorizer()         0.768107   \n",
       "4                               TfidfVectorizer()         0.768052   \n",
       "\n",
       "   rank_test_score  mean_fit_time  mean_score_time  \n",
       "0                1      76.192374         5.484644  \n",
       "1                2     224.143465         5.005721  \n",
       "2                3      14.457293         1.685853  \n",
       "3                4      13.656884         1.708761  \n",
       "4                5      14.293548         1.601098  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_result = (pd.DataFrame(model_grid.cv_results_)\n",
    "  [['param_regressor', 'param_vect', 'mean_test_score', 'rank_test_score', 'mean_fit_time', 'mean_score_time']]\n",
    "   .sort_values(by='mean_test_score', ascending=False)\n",
    "  ).reset_index(drop=True)\n",
    "vect_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7740497821944208"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_result.query('(param_vect==@tfidf_vectorizer) and (param_regressor==@model_lgb)').mean_test_score.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сохраним результаты в итоговую таблицу**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result['LGBMClassifier']\n",
    " .append(\n",
    "     round(\n",
    "         vect_result.query('(param_vect==@tfidf_vectorizer) and (param_regressor==@model_lgb)')\n",
    "         .mean_test_score\n",
    "         .max(), 3)\n",
    " )\n",
    ")\n",
    "\n",
    "(result['LGBMClassifier']\n",
    " .append(\n",
    "     round(\n",
    "         vect_result.query('(param_vect==@count_vect) and (param_regressor==@model_lgb)')\n",
    "         .mean_test_score\n",
    "         .max(), 3)\n",
    " )\n",
    ")\n",
    "\n",
    "(result['LogisticRegression']\n",
    " .append(\n",
    "     round(\n",
    "         vect_result.query('(param_vect==@tfidf_vectorizer) and (param_regressor==@model)')\n",
    "         .mean_test_score\n",
    "         .max(), 3)\n",
    " )\n",
    ")\n",
    "\n",
    "\n",
    "(result['LogisticRegression']\n",
    " .append(\n",
    "     round(\n",
    "         vect_result.query('(param_vect==@count_vect) and (param_regressor==@model)')\n",
    "         .mean_test_score\n",
    "         .max(), 3)\n",
    " )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выгружаем лучшую модель в файл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# save\n",
    "joblib.dump(model_grid.best_estimator_, \"model.pkl\")\n",
    "# load\n",
    "#clf2 = joblib.load(\"model.pkl\")\n",
    "#clf2.predict(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BERT</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>CountVectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.579</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.654</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BERT  TF-IDF  CountVectorizer\n",
       "LGBMClassifier      0.579   0.774            0.778\n",
       "LogisticRegression  0.654   0.768            0.760"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(result, orient='index', columns=['BERT', 'TF-IDF', 'CountVectorizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Лучший результат показала LGBMClassifier c CountVectorizer. Проверим ее на тесте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тестирование**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7870852551703617"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_grid.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверим модель на адекватность**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18446546614998857"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, np.ones(len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В выборке почти 160000 строк. Из них негативные только 10%.\n",
    "\n",
    "**Обучение моделей с BERT**\n",
    "\n",
    "Для экономии времени было взято 200 объектов сохранив исходный дисбаланс класов целевого признака.\n",
    "Использовали предобученную модель Conversational BERT, English с домена <a href='https://docs.deeppavlov.ai/en/master/features/models/bert.html'> DeepPavlov</a>. Лучший результат у LogisticRegression, f1 = 0.626. Но все же он намного ниже требуемого. Возможно с увеличением количества объектов увеличится и качество модели.\n",
    "\n",
    "**Обучение моделей с TF-IDF и CountVectorizer**\n",
    "\n",
    "Для предподготовки текста использовали библиотеку nltk. Лучший результат показала LGBMClassifier c CountVectorizer, f1 = 0.778.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "На тестовой выборке модель показала f1 = 0.787"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
